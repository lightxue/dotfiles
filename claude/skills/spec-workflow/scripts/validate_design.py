#!/usr/bin/env python3
"""
éªŒè¯è®¾è®¡æ–¹æ¡ˆæ–‡æ¡£ï¼ˆdesign.mdï¼‰çš„å®Œæ•´æ€§

æ£€æŸ¥é¡¹ï¼š
- å¿…éœ€ç« èŠ‚æ˜¯å¦å­˜åœ¨
- mermaid å›¾è¯­æ³•æ˜¯å¦æ­£ç¡®
- æ­§ä¹‰æ¸…å•æ ¼å¼æ˜¯å¦è§„èŒƒ
- æ–‡æ¡£å¤´ä¿¡æ¯æ˜¯å¦å®Œæ•´

è¿”å›æ ¼å¼ï¼šJSON
é€€å‡ºç ï¼š0=æˆåŠŸ, 1=éªŒè¯å¤±è´¥, 2=å¼‚å¸¸é”™è¯¯
"""

import sys
import re
import json
from pathlib import Path
from typing import Any

# å¿…éœ€ç« èŠ‚åˆ—è¡¨ï¼ˆåŸºäº design.md.templateï¼‰
REQUIRED_SECTIONS = [
    "æ¦‚è¿°",  # åŒ…å«ã€Œéœ€æ±‚è¯´æ˜ã€ã€Œè¿­ä»£ç›®æ ‡ã€ã€Œé¡¹ç›®ç°çŠ¶åˆ†æã€
    "æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•",
    "æ¶æ„è®¾è®¡",
    "æ”¹åŠ¨åˆ†æ",  # åŒ…å«ã€Œæ–°å¢æ¨¡å—ã€ã€Œä¿®æ”¹æ¨¡å—ã€ï¼Œã€Œåˆ é™¤æ¨¡å—ã€ä¸ºå¯é€‰
    "ä¾èµ–æœåŠ¡è°ƒç”¨",
    "æ¥å£ä¸æ•°æ®",
    "æŠ€æœ¯éš¾ç‚¹ä¸å¯¹ç­–",
    "é£é™©è¯†åˆ«ä¸åº”å¯¹"  # ç²¾ç®€åï¼šåˆ é™¤äº†"æµ‹è¯•ç­–ç•¥"ã€"ç°åº¦æ–¹æ¡ˆ"ã€"å›æ»šæ–¹æ¡ˆ"
]

# å¿…éœ€å­ç« èŠ‚ï¼ˆæé«˜æ–‡æ¡£è´¨é‡è¦æ±‚ï¼‰
REQUIRED_SUBSECTIONS = {
    "æ¦‚è¿°": ["éœ€æ±‚è¯´æ˜", "è¿­ä»£ç›®æ ‡", "é¡¹ç›®ç°çŠ¶åˆ†æ"],
    "æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•": ["éœ€æ±‚ç†è§£ç–‘é—®", "æŠ€æœ¯æ–¹æ¡ˆå¾…å®šé¡¹", "è¾¹ç•Œæ¡ä»¶ç¡®è®¤"],
    "æ¶æ„è®¾è®¡": ["æ•´ä½“æ¶æ„", "æ”¹åŠ¨è¯´æ˜"],
    "æ”¹åŠ¨åˆ†æ": ["æ–°å¢æ¨¡å—", "ä¿®æ”¹æ¨¡å—"]  # åˆ é™¤æ¨¡å—ä¸ºå¯é€‰ç« èŠ‚
    # æ³¨æ„ï¼š"æ¥å£ä¸æ•°æ®"å­ç« èŠ‚ä¸ºå¯é€‰ï¼ˆæ ¹æ®å®é™…éœ€æ±‚å¯èƒ½ä¸ºç©ºï¼‰
    # æ³¨æ„ï¼š"ä¾èµ–æœåŠ¡è°ƒç”¨"æœ‰äº’æ–¥å­ç« èŠ‚ï¼Œç”±ä¸“é—¨å‡½æ•°éªŒè¯
    # ç²¾ç®€åï¼šåˆ é™¤äº†"æµ‹è¯•ç­–ç•¥"ã€"ç°åº¦æ–¹æ¡ˆ"ã€"å›æ»šæ–¹æ¡ˆ"çš„å¿…éœ€æ€§æ£€æŸ¥
    # åŸå› ï¼šæµ‹è¯•ç­–ç•¥å±äºæ‰§è¡Œé˜¶æ®µã€ç°åº¦/å›æ»šå±äºè¿ç»´SOPï¼Œä¸åº”åœ¨è®¾è®¡æ–‡æ¡£ä¸­å¼ºåˆ¶è¦æ±‚
}

# æ–‡æ¡£å¤´å¿…éœ€å­—æ®µï¼ˆåŸºäº design.md.templateï¼‰
REQUIRED_HEADERS = [
    "åˆ›å»ºæ—¶é—´",
    "éœ€æ±‚æ¥æº"
]


def validate_file_exists(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    path = Path(file_path)
    if not path.exists():
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {file_path}")
        return False
    if not path.is_file():
        print(f"âŒ é”™è¯¯ï¼šä¸æ˜¯æ–‡ä»¶ - {file_path}")
        return False
    return True


def validate_file_path(file_path: str) -> tuple[list[str], list[str]]:
    """éªŒè¯æ–‡ä»¶è·¯å¾„æ ¼å¼æ˜¯å¦ç¬¦åˆè§„èŒƒ

    æ£€æŸ¥é¡¹ï¼š
    - æ–‡ä»¶åå¿…é¡»ä¸º design.md
    - å»ºè®®åœ¨ .specs/ ç›®å½•ä¸‹
    - ç›®å½•å‘½åæ ¼å¼ï¼š{feature_name}-{requirement_id}
    - requirement_id æ ¼å¼ï¼šTAPDä¸º19ä½æ•°å­—ï¼Œæ–‡å­—æè¿°ä¸ºYYYYMMDDXXX
    """
    errors: list[str] = []
    warnings: list[str] = []

    path = Path(file_path)

    # 1. æ£€æŸ¥æ–‡ä»¶å
    if path.name != 'design.md':
        errors.append(f"æ–‡ä»¶åé”™è¯¯ï¼šæœŸæœ› 'design.md'ï¼Œå®é™… '{path.name}'")

    # 2. æ£€æŸ¥æ˜¯å¦åœ¨ .specs/ ç›®å½•ä¸‹
    path_str = str(path.resolve())
    if '.specs' not in path_str:
        warnings.append((
            f"å»ºè®®å°†æ–‡ä»¶æ”¾åœ¨ .specs/ ç›®å½•ä¸‹\n"
            f"  å½“å‰è·¯å¾„ï¼š{path_str}\n"
            f"  æ¨èè·¯å¾„ï¼š.specs/{{feature_name}}-{{requirement_id}}/design.md"
        ))
    else:
        # 3. æ£€æŸ¥ç›®å½•å‘½åæ ¼å¼
        parent_name = path.parent.name

        if '-' not in parent_name:
            warnings.append((
                f"ç›®å½•å‘½åä¸ç¬¦åˆè§„èŒƒï¼š'{parent_name}'\n"
                f"  æœŸæœ›æ ¼å¼ï¼š{{feature_name}}-{{requirement_id}}\n"
                f"  ç¤ºä¾‹ï¼šh5-subscribe-optimize-1020426960128093915"
            ))
        else:
            # åˆ†ç¦» feature_name å’Œ requirement_idï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            parts = parent_name.rsplit('-', 1)
            if len(parts) == 2:
                feature_name, _ = parts

                # éªŒè¯ feature_nameï¼ˆåŸºæœ¬æ£€æŸ¥ï¼‰
                if not feature_name:
                    warnings.append("feature_name ä¸èƒ½ä¸ºç©º")
                elif not re.match(r'^[a-z0-9-]+$', feature_name):
                    warnings.append((
                        f"feature_name å»ºè®®ä½¿ç”¨å°å†™å­—æ¯ã€æ•°å­—å’Œè¿å­—ç¬¦ï¼š'{feature_name}'\n"
                        f"  æ¨èæ ¼å¼ï¼šuser-login, h5-subscribe-optimize"
                    ))

    return errors, warnings


def validate_headers(content: str) -> list[str]:
    """éªŒè¯æ–‡æ¡£å¤´ä¿¡æ¯"""
    errors: list[str] = []

    # æå–æ–‡æ¡£å¤´ä¿¡æ¯ï¼ˆä»¥ > å¼€å¤´çš„è¡Œï¼‰
    header_lines = [line.strip() for line in content.split('\n') if line.strip().startswith('>')]

    for required_header in REQUIRED_HEADERS:
        found = any(required_header in line for line in header_lines)
        if not found:
            errors.append(f"ç¼ºå°‘æ–‡æ¡£å¤´å­—æ®µï¼š{required_header}")

    return errors


def validate_sections(content: str) -> tuple[list[str], list[str]]:
    """éªŒè¯å¿…éœ€ç« èŠ‚å’Œå­ç« èŠ‚ï¼ˆåŸºäº design.md.templateï¼‰

    æ”¯æŒçš„ç« èŠ‚å±‚çº§å’Œæ ¼å¼ï¼š
    - ## ç« èŠ‚åï¼ˆäºŒçº§æ ‡é¢˜ï¼‰
    - ### ç« èŠ‚åï¼ˆä¸‰çº§æ ‡é¢˜ï¼‰
    - #### ç« èŠ‚åï¼ˆå››çº§æ ‡é¢˜ï¼‰
    - ## 1. ç« èŠ‚åï¼ˆå¸¦åºå·ï¼‰
    """
    errors: list[str] = []
    warnings: list[str] = []

    # 1. éªŒè¯å¿…éœ€ä¸»ç« èŠ‚
    for section in REQUIRED_SECTIONS:
        # æ”¯æŒå¸¦åºå·å’Œä¸å¸¦åºå·ä¸¤ç§æ ¼å¼
        pattern1 = r'^##\s+' + re.escape(section) + r'(?:\s|$)'
        pattern2 = r'^##\s+\d+\.\s*' + re.escape(section) + r'(?:\s|$)'

        if not (re.search(pattern1, content, re.MULTILINE) or re.search(pattern2, content, re.MULTILINE)):
            errors.append(f"ç¼ºå°‘å¿…éœ€ç« èŠ‚ï¼š## {section}")

    # 2. éªŒè¯å¿…éœ€å­ç« èŠ‚ï¼ˆæ›´ä¸¥æ ¼çš„è´¨é‡è¦æ±‚ï¼‰
    for main_section, subsections in REQUIRED_SUBSECTIONS.items():
        # å…ˆæ‰¾åˆ°ä¸»ç« èŠ‚å†…å®¹
        # ä¿®å¤ï¼šä½¿ç”¨ ^##\s+(?!#) ç¡®ä¿åªåŒ¹é…ä¸¤ä¸ª # çš„æ ‡é¢˜
        # ä¸åŒ¹é… ### æˆ–æ›´å¤š
        section_pattern = (
            r'^##\s+(?!#)(?:\d+\.\s*)?' +
            re.escape(main_section) +
            r'\s*(.*?)(?=^##\s+(?!#)|\Z)'
        )
        section_match = re.search(section_pattern, content, re.DOTALL | re.MULTILINE)

        if section_match:
            section_content = section_match.group(1)

            # æ£€æŸ¥æ¯ä¸ªå¿…éœ€å­ç« èŠ‚
            for subsection in subsections:
                # åŒ¹é…ä¸‰çº§æˆ–å››çº§æ ‡é¢˜
                sub_pattern1 = r'^###\s+(?:\d+\.\d+\.?\s*)?' + re.escape(subsection)
                sub_pattern2 = r'^####\s+(?:\d+\.\d+\.\d+\.?\s*)?' + re.escape(subsection)

                if not (re.search(sub_pattern1, section_content, re.MULTILINE) or
                        re.search(sub_pattern2, section_content, re.MULTILINE)):
                    warnings.append(
                        f"å»ºè®®åœ¨ã€Œ{main_section}ã€ç« èŠ‚æ·»åŠ å­ç« èŠ‚ï¼š### {subsection}"
                    )

    return errors, warnings


def validate_mermaid(content: str) -> tuple[list[str], list[str]]:
    """éªŒè¯ mermaid å›¾è¯­æ³•"""
    errors: list[str] = []
    warnings: list[str] = []

    # æŸ¥æ‰¾æ‰€æœ‰ mermaid ä»£ç å—
    mermaid_blocks = re.findall(r'```mermaid\n(.*?)\n```', content, re.DOTALL)

    if not mermaid_blocks:
        warnings.append("æœªæ‰¾åˆ° mermaid æµç¨‹å›¾ï¼Œå»ºè®®æ·»åŠ æ¶æ„å›¾")

    for i, block in enumerate(mermaid_blocks, 1):
        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
        if not block.strip():
            errors.append(f"ç¬¬ {i} ä¸ª mermaid å›¾ä¸ºç©º")
            continue

        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç±»å‹å£°æ˜
        graph_types = ['graph', 'sequenceDiagram', 'classDiagram', 'stateDiagram', 'erDiagram']
        has_type = any(gtype in block for gtype in graph_types)
        if not has_type:
            errors.append(f"ç¬¬ {i} ä¸ª mermaid å›¾ç¼ºå°‘å›¾ç±»å‹å£°æ˜")

    return errors, warnings


def validate_ambiguity_list(content: str) -> tuple[list[str], list[str]]:
    """éªŒè¯æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•æ ¼å¼ï¼ˆå¼ºåˆ¶æ£€æŸ¥æœªå‹¾é€‰é¡¹ï¼‰"""
    errors: list[str] = []
    warnings: list[str] = []

    # æŸ¥æ‰¾æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•ç« èŠ‚ï¼ˆæ”¯æŒ ## æˆ– # æ ‡é¢˜ï¼‰
    ambiguity_pattern = r'#{1,2}\s+æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•(.*?)(?=\n#{1,2}\s+|\Z)'
    match = re.search(ambiguity_pattern, content, re.DOTALL)

    if not match:
        errors.append("ç¼ºå°‘ã€Œæ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•ã€ç« èŠ‚")
        return errors, warnings

    ambiguity_section = match.group(1)

    # æ£€æŸ¥æ˜¯å¦æ˜ç¡®æ ‡æ³¨ã€Œæ— ã€
    if 'æ— ' in ambiguity_section or 'ã€Œæ— ã€' in ambiguity_section:
        return errors, warnings  # æ˜ç¡®æ ‡æ³¨æ— æ­§ä¹‰ï¼Œé€šè¿‡æ£€æŸ¥

    # æŸ¥æ‰¾æ‰€æœ‰æœªå‹¾é€‰çš„å¾…ç¡®è®¤é¡¹ï¼ˆ- [ ] æˆ– - []ï¼‰
    unchecked_items = re.findall(r'-\s*\[\s*\]\s*(.+)', ambiguity_section)

    # æŸ¥æ‰¾æ‰€æœ‰å·²å‹¾é€‰çš„å¾…ç¡®è®¤é¡¹ï¼ˆ- [x] æˆ– - [X]ï¼‰
    checked_items = re.findall(r'-\s*\[[xX]\]\s*(.+)', ambiguity_section)

    # å…³é”®æ£€æŸ¥ï¼šå¦‚æœæœ‰æœªå‹¾é€‰é¡¹ï¼Œä½œä¸º ERROR è€Œé warning
    if unchecked_items:
        errors.append(
            f"âŒ å­˜åœ¨ {len(unchecked_items)} ä¸ªæœªè§£å†³çš„å¾…ç¡®è®¤é—®é¢˜ï¼Œå¿…é¡»å…¨éƒ¨æ¾„æ¸…åæ‰èƒ½å®¡æ‰¹é€šè¿‡ï¼"
        )
        # åˆ—å‡ºå‰3ä¸ªæœªè§£å†³çš„é—®é¢˜
        for i, item in enumerate(unchecked_items[:3], 1):
            errors.append(f"   {i}. [ ] {item.strip()}")
        if len(unchecked_items) > 3:
            errors.append(f"   ... è¿˜æœ‰ {len(unchecked_items) - 3} ä¸ªæœªè§£å†³é—®é¢˜")
        errors.append("")
        errors.append("ğŸ’¡ è§£å†³æ–¹æ³•ï¼š")
        errors.append("   1. é€ä¸€æ¾„æ¸…æ¯ä¸ªå¾…ç¡®è®¤é—®é¢˜")
        errors.append("   2. å°†å·²æ¾„æ¸…çš„é—®é¢˜æ”¹ä¸º - [x]ï¼ˆå‹¾é€‰ï¼‰")
        errors.append("   3. æˆ–æ˜ç¡®æ ‡æ³¨ã€Œæ— ã€å¦‚æœç¡®å®æ²¡æœ‰å¾…ç¡®è®¤é—®é¢˜")

    # å¦‚æœæ—¢æ²¡æœ‰å¾…ç¡®è®¤é¡¹ï¼Œä¹Ÿæ²¡æœ‰æ ‡æ³¨ã€Œæ— ã€
    if not unchecked_items and not checked_items:
        warnings.append("æ­§ä¹‰ä¸å¾…ç¡®è®¤æ¸…å•ä¸ºç©ºï¼Œå¦‚æ— æ­§ä¹‰è¯·æ˜ç¡®æ ‡æ³¨ã€Œæ— ã€")

    return errors, warnings


def validate_dependency_services(content: str) -> tuple[list[str], list[str]]:
    """éªŒè¯ä¾èµ–æœåŠ¡è°ƒç”¨ç« èŠ‚ï¼ˆä¸æ¨¡æ¿ä¿æŒä¸€è‡´ï¼‰

    æ¨¡æ¿å®šä¹‰äº†3ä¸ªäº’æ–¥çš„å­ç« èŠ‚ï¼š
    - ### åŒ»ä¿æœåŠ¡ä¾èµ–ï¼ˆå¦‚ä¸æ¶‰åŠè¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰
    - ### é€šç”¨ç»„ä»¶ä¾èµ–ï¼ˆå¦‚ä¸æ¶‰åŠè¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰
    - ### æ— ä¾èµ–æœåŠ¡è°ƒç”¨ï¼ˆå¦‚æ¶‰åŠä¾èµ–æœåŠ¡è¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰

    éªŒè¯è§„åˆ™ï¼šå¿…é¡»è‡³å°‘åŒ…å«å…¶ä¸­1ä¸ªå­ç« èŠ‚
    """
    errors: list[str] = []
    warnings: list[str] = []

    # æŸ¥æ‰¾ä¾èµ–æœåŠ¡è°ƒç”¨ç« èŠ‚ï¼ˆä¿®å¤ï¼šä½¿ç”¨ (?!#) ç¡®ä¿åªåŒ¹é…äºŒçº§æ ‡é¢˜ï¼‰
    dependency_pattern = r'##\s+(?!#)ä¾èµ–æœåŠ¡è°ƒç”¨(.*?)(?=^##\s+(?!#)|\Z)'
    match = re.search(dependency_pattern, content, re.DOTALL | re.MULTILINE)

    if not match:
        errors.append("ç¼ºå°‘ã€Œä¾èµ–æœåŠ¡è°ƒç”¨ã€ç« èŠ‚")
        return errors, warnings

    section_content = match.group(1).strip()

    # æ£€æŸ¥3ä¸ªäº’æ–¥å­ç« èŠ‚æ˜¯å¦è‡³å°‘å­˜åœ¨1ä¸ª
    has_medical_service = bool(re.search(r'###\s+åŒ»ä¿æœåŠ¡ä¾èµ–', section_content))
    has_common_component = bool(re.search(r'###\s+é€šç”¨ç»„ä»¶ä¾èµ–', section_content))
    has_no_dependency = bool(re.search(r'###\s+æ— ä¾èµ–æœåŠ¡è°ƒç”¨', section_content))

    # ç»Ÿè®¡æœ‰å¤šå°‘ä¸ªå­ç« èŠ‚
    subsection_count = sum([has_medical_service, has_common_component, has_no_dependency])

    if subsection_count == 0:
        errors.append(
            "ã€Œä¾èµ–æœåŠ¡è°ƒç”¨ã€ç« èŠ‚å¿…é¡»åŒ…å«ä»¥ä¸‹å­ç« èŠ‚ä¹‹ä¸€ï¼š\n"
            "  - ### åŒ»ä¿æœåŠ¡ä¾èµ–ï¼ˆå¦‚ä¸æ¶‰åŠè¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰\n"
            "  - ### é€šç”¨ç»„ä»¶ä¾èµ–ï¼ˆå¦‚ä¸æ¶‰åŠè¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰\n"
            "  - ### æ— ä¾èµ–æœåŠ¡è°ƒç”¨ï¼ˆå¦‚æ¶‰åŠä¾èµ–æœåŠ¡è¯·åˆ é™¤æ­¤å°èŠ‚ï¼‰"
        )
    elif subsection_count > 1:
        # å¦‚æœåŒæ—¶å­˜åœ¨å¤šä¸ªå­ç« èŠ‚ï¼Œç»™å‡ºè­¦å‘Šï¼ˆé€šå¸¸åº”è¯¥åˆ é™¤ä¸ç›¸å…³çš„ï¼‰
        present_subsections = []
        if has_medical_service:
            present_subsections.append("åŒ»ä¿æœåŠ¡ä¾èµ–")
        if has_common_component:
            present_subsections.append("é€šç”¨ç»„ä»¶ä¾èµ–")
        if has_no_dependency:
            present_subsections.append("æ— ä¾èµ–æœåŠ¡è°ƒç”¨")

        warnings.append(
            f"ã€Œä¾èµ–æœåŠ¡è°ƒç”¨ã€ç« èŠ‚åŒ…å«å¤šä¸ªå­ç« èŠ‚ï¼š{', '.join(present_subsections)}\n"
            "  å»ºè®®ï¼šå¦‚æœæœ‰ä¾èµ–æœåŠ¡ï¼Œåˆ é™¤ã€Œæ— ä¾èµ–æœåŠ¡è°ƒç”¨ã€ï¼›å¦‚æœæ— ä¾èµ–ï¼Œåˆ é™¤å…¶ä»–å­ç« èŠ‚"
        )

    return errors, warnings


def validate_interfaces_and_data(content: str) -> tuple[list[str], list[str]]:
    """éªŒè¯æ¥å£ä¸æ•°æ®ç« èŠ‚ï¼ˆå…è®¸å­ç« èŠ‚ä¸ºç©ºï¼‰

    æ¨¡æ¿å®šä¹‰äº†3ä¸ªå­ç« èŠ‚ï¼š
    - ### æ–°å¢æ¥å£ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    - ### ä¿®æ”¹æ¥å£ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
    - ### æ•°æ®æ¨¡å‹ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰

    éªŒè¯è§„åˆ™ï¼šè‡³å°‘éœ€è¦è¯´æ˜æ˜¯å¦æœ‰æ¥å£æ”¹åŠ¨
    """
    errors: list[str] = []
    warnings: list[str] = []

    # æŸ¥æ‰¾æ¥å£ä¸æ•°æ®ç« èŠ‚
    interface_pattern = r'##\s+(?!#)æ¥å£ä¸æ•°æ®(.*?)(?=^##\s+(?!#)|\Z)'
    match = re.search(interface_pattern, content, re.DOTALL | re.MULTILINE)

    if not match:
        errors.append("ç¼ºå°‘ã€Œæ¥å£ä¸æ•°æ®ã€ç« èŠ‚")
        return errors, warnings

    section_content = match.group(1).strip()

    # æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬çš„å­ç« èŠ‚è¯´æ˜
    has_new_interface = bool(re.search(r'###\s+æ–°å¢æ¥å£', section_content))
    has_modified_interface = bool(re.search(r'###\s+ä¿®æ”¹æ¥å£', section_content))
    has_data_model = bool(re.search(r'###\s+æ•°æ®æ¨¡å‹', section_content))

    # å¦‚æœ3ä¸ªå­ç« èŠ‚éƒ½æ²¡æœ‰ï¼Œç»™å‡ºè­¦å‘Š
    if not (has_new_interface or has_modified_interface or has_data_model):
        warnings.append(
            "ã€Œæ¥å£ä¸æ•°æ®ã€ç« èŠ‚å»ºè®®åŒ…å«ä»¥ä¸‹å­ç« èŠ‚ä¹‹ä¸€ï¼š\n"
            "  - ### æ–°å¢æ¥å£ï¼ˆå¦‚æ— æ–°å¢æ¥å£å¯æ ‡æ³¨ã€Œæ— ã€ï¼‰\n"
            "  - ### ä¿®æ”¹æ¥å£ï¼ˆå¦‚æ— ä¿®æ”¹æ¥å£å¯æ ‡æ³¨ã€Œæ— ã€ï¼‰\n"
            "  - ### æ•°æ®æ¨¡å‹ï¼ˆå¦‚æ— æ•°æ®æ¨¡å‹å¯æ ‡æ³¨ã€Œæ— ã€ï¼‰"
        )

    return errors, warnings


def validate_design(file_path: str) -> dict[str, Any]:
    """ä¸»éªŒè¯å‡½æ•° - è¿”å›ç»“æ„åŒ–æ•°æ®"""
    all_errors: list[str] = []
    all_warnings: list[str] = []

    # 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not validate_file_exists(file_path):
        return {
            "success": False,
            "errors": [f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {file_path}"],
            "warnings": [],
            "suggestions": ["æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®", "ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨"]
        }

    # 2. éªŒè¯æ–‡ä»¶è·¯å¾„æ ¼å¼
    errors, warnings = validate_file_path(file_path)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # 3. è¯»å–æ–‡ä»¶å†…å®¹
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except (IOError, OSError) as e:
        return {
            "success": False,
            "errors": [f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"],
            "warnings": [],
            "suggestions": ["æ£€æŸ¥æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸º UTF-8", "ç¡®è®¤æ–‡ä»¶æƒé™"]
        }

    # 4. éªŒè¯æ–‡æ¡£å¤´ä¿¡æ¯
    errors = validate_headers(content)
    all_errors.extend(errors)

    # 5. éªŒè¯å¿…éœ€ç« èŠ‚å’Œå­ç« èŠ‚
    errors, warnings = validate_sections(content)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # 6. éªŒè¯ mermaid å›¾
    errors, warnings = validate_mermaid(content)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # 7. éªŒè¯æ­§ä¹‰æ¸…å•
    errors, warnings = validate_ambiguity_list(content)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # 8. éªŒè¯ä¾èµ–æœåŠ¡
    errors, warnings = validate_dependency_services(content)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # 9. éªŒè¯æ¥å£ä¸æ•°æ®
    errors, warnings = validate_interfaces_and_data(content)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    # æ„å»ºä¿®å¤å»ºè®®
    suggestions = []
    if all_errors:
        suggestions.append("è¯·ä¿®å¤ä¸Šè¿°é”™è¯¯åé‡æ–°éªŒè¯")
        if "ç¼ºå°‘å¿…éœ€ç« èŠ‚" in str(all_errors):
            suggestions.append("å‚è€ƒ assets/templates/design.md.template æ¨¡æ¿è¡¥å……ç¼ºå¤±ç« èŠ‚")
        if "ç¼ºå°‘æ–‡æ¡£å¤´å­—æ®µ" in str(all_errors):
            suggestions.append("å‚è€ƒ assets/templates/design.md.template æ¨¡æ¿è¡¥å……æ–‡æ¡£å¤´")

    if all_warnings and not all_errors:
        suggestions.append("å»ºè®®æ”¹è¿›è­¦å‘Šé¡¹åå†æäº¤å®¡æ‰¹")

    # è¿”å›ç»“æ„åŒ–ç»“æœ
    return {
        "success": len(all_errors) == 0,
        "errors": all_errors,
        "warnings": all_warnings,
        "suggestions": suggestions,
        "stats": {
            "error_count": len(all_errors),
            "warning_count": len(all_warnings)
        }
    }


def main() -> None:
    """ä¸»ç¨‹åºå…¥å£ - æ”¯æŒ JSON è¾“å‡ºæ¨¡å¼"""
    import argparse  # pylint: disable=import-outside-toplevel

    parser = argparse.ArgumentParser(
        description='éªŒè¯è®¾è®¡æ–¹æ¡ˆæ–‡æ¡£æ ¼å¼è§„èŒƒ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    _ = parser.add_argument('file_path', help='è®¾è®¡æ–¹æ¡ˆæ–‡æ¡£è·¯å¾„ï¼ˆå¦‚ .specs/xxx/design.mdï¼‰')
    _ = parser.add_argument('--json', action='store_true', help='JSON æ ¼å¼è¾“å‡ºï¼ˆç”¨äºè‡ªåŠ¨åŒ–ï¼‰')
    _ = parser.add_argument('--quiet', action='store_true', help='é™é»˜æ¨¡å¼ï¼ˆä»…è¾“å‡º JSONï¼‰')

    args = parser.parse_args()

    # æ‰§è¡ŒéªŒè¯
    result = validate_design(args.file_path)

    # JSON è¾“å‡ºæ¨¡å¼
    if args.json or args.quiet:
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0 if result["success"] else 1)

    # äººç±»å¯è¯»è¾“å‡ºæ¨¡å¼ï¼ˆåŸæœ‰æ ¼å¼ï¼‰
    print(f"\n{'='*60}")
    print(f"ğŸ“„ éªŒè¯è®¾è®¡æ–¹æ¡ˆæ–‡æ¡£ï¼š{args.file_path}")
    print(f"{'='*60}\n")

    if result["errors"]:
        print("âŒ å‘ç°ä»¥ä¸‹é”™è¯¯ï¼ˆå¿…é¡»ä¿®å¤ï¼‰ï¼š\n")
        for i, error in enumerate(result["errors"], 1):
            print(f"  {i}. {error}")
        print()

    if result["warnings"]:
        print("âš ï¸  å‘ç°ä»¥ä¸‹è­¦å‘Šï¼ˆå»ºè®®æ”¹è¿›ï¼‰ï¼š\n")
        for i, warning in enumerate(result["warnings"], 1):
            print(f"  {i}. {warning}")
        print()

    if not result["errors"] and not result["warnings"]:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼è®¾è®¡æ–¹æ¡ˆæ–‡æ¡£æ ¼å¼è§„èŒƒã€‚\n")
    elif not result["errors"]:
        print("âš ï¸  æ ¼å¼æ£€æŸ¥é€šè¿‡ï¼Œä½†å­˜åœ¨è­¦å‘Šé¡¹ï¼Œå»ºè®®æ”¹è¿›åå†æäº¤å®¡æ‰¹ã€‚\n")
    else:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼šå‘ç° {len(result['errors'])} ä¸ªé”™è¯¯ï¼Œ{len(result['warnings'])} ä¸ªè­¦å‘Š\n")

    if result["suggestions"]:
        print("ğŸ’¡ ä¿®å¤å»ºè®®ï¼š\n")
        for i, suggestion in enumerate(result["suggestions"], 1):
            print(f"  {i}. {suggestion}")
        print()

    # é€€å‡ºç ï¼š0=æˆåŠŸï¼Œ1=éªŒè¯å¤±è´¥
    sys.exit(0 if result["success"] else 1)


if __name__ == "__main__":
    main()
