#!/usr/bin/env python3
"""
éªŒè¯ wiki æ–‡æ¡£ï¼ˆ1+3æ–‡æ¡£ç»“æ„ï¼‰çš„å®Œæ•´æ€§

æ£€æŸ¥é¡¹ï¼š
- 4ä¸ªæ–‡æ¡£æ˜¯å¦å­˜åœ¨ï¼ˆREADME + architecture + interfaces + implementationï¼‰
- å¿…éœ€ç« èŠ‚æ˜¯å¦å®Œæ•´
- mermaid å›¾æ•°é‡å’Œè´¨é‡
- æ¥å£æ–‡æ¡£è¡¨æ ¼æ ¼å¼
- ä»£ç ä½ç½®æ ‡æ³¨
- å ä½ç¬¦æ£€æŸ¥

è¿”å›æ ¼å¼ï¼šJSON
é€€å‡ºç ï¼š0=æˆåŠŸ, 1=éªŒè¯å¤±è´¥, 2=å¼‚å¸¸é”™è¯¯
"""

import sys
import re
import json
import argparse
from pathlib import Path

# 1+3æ–‡æ¡£ç»“æ„å®šä¹‰
DOC_STRUCTURE = {
    "README.md": {
        "required_sections": ["å¿«é€Ÿå¯¼èˆª", "é¡¹ç›®ç»“æ„", "æ ¸å¿ƒæ¨¡å—"],
        "min_mermaid": 0,  # READMEä¸å¼ºåˆ¶è¦æ±‚mermaidå›¾
        "description": "å…¥å£ç´¢å¼• - é¡¹ç›®æ¦‚è§ˆã€å¿«é€Ÿå¯¼èˆªã€æ ¸å¿ƒæ¨¡å—"
    },
    "architecture.md": {
        "required_sections": ["æ•´ä½“æ¶æ„", "æ¨¡å—åˆ’åˆ†", "æ•°æ®æ¨¡å‹", "æŠ€æœ¯é€‰å‹"],
        "min_mermaid": 1,  # è‡³å°‘1ä¸ªæ¶æ„å›¾
        "description": "æ¶æ„æ ¸å¿ƒ - æ¶æ„è®¾è®¡ã€æ¨¡å—åˆ’åˆ†ã€æ•°æ®æ¨¡å‹"
    },
    "interfaces.md": {
        "required_sections": ["æ¥å£æ€»è§ˆ", "æ ¸å¿ƒæ¥å£è¯¦ç»†å®šä¹‰"],
        "min_mermaid": 0,  # æµç¨‹å›¾åœ¨implementation.md
        "description": "æ¥å£æ±‡æ€» - æ¥å£æ¸…å•ã€è¯·æ±‚å“åº”å®šä¹‰"
    },
    "implementation.md": {
        "required_sections": ["æ ¸å¿ƒä¸šåŠ¡æµç¨‹", "å…³é”®å®ç°ç‚¹"],
        "min_mermaid": 1,  # è‡³å°‘1ä¸ªæ ¸å¿ƒæµç¨‹å›¾ï¼ˆç²¾ç®€åå‡å°‘è¦æ±‚ï¼‰
        "description": "å®ç°ç»†èŠ‚ - ä¸šåŠ¡æµç¨‹å›¾ã€å…³é”®å®ç°è¯´æ˜"
    }
}

# å ä½ç¬¦å…³é”®è¯
PLACEHOLDER_KEYWORDS = [
    "TODO", "å¾…è¡¥å……", "å¾…å®Œå–„", "TBD", "å¾…æ·»åŠ ", "å¾…å®ç°", "å¾…ç¡®è®¤"
]

# æœ€å°ç« èŠ‚å†…å®¹å­—æ•°
MIN_SECTION_LENGTH = 50


def validate_directory_structure(doc_dir):
    """éªŒè¯docç›®å½•ç»“æ„å’Œæ–‡æ¡£å­˜åœ¨æ€§"""
    errors = []
    warnings = []

    doc_path = Path(doc_dir)

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not doc_path.exists():
        errors.append(f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {doc_dir}")
        return errors, warnings, {}

    if not doc_path.is_dir():
        errors.append(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {doc_dir}")
        return errors, warnings, {}

    # æ£€æŸ¥4ä¸ªæ–‡æ¡£æ˜¯å¦éƒ½å­˜åœ¨
    found_docs = {}
    for doc_name in DOC_STRUCTURE:
        doc_file = doc_path / doc_name
        if doc_file.exists():
            found_docs[doc_name] = str(doc_file)
        else:
            errors.append(f"ç¼ºå°‘æ–‡æ¡£: {doc_name}")

    # å¦‚æœæœ‰ç¼ºå¤±æ–‡æ¡£ï¼Œç›´æ¥è¿”å›
    if len(found_docs) != 4:
        warnings.append(
            f"æ–‡æ¡£ä¸å®Œæ•´ï¼ŒæœŸæœ›4ä¸ªæ–‡æ¡£ï¼Œå®é™…æ‰¾åˆ°{len(found_docs)}ä¸ª\n"
            f"  æœŸæœ›æ–‡æ¡£: {', '.join(DOC_STRUCTURE.keys())}\n"
            f"  å·²æ‰¾åˆ°: {', '.join(found_docs.keys())}"
        )

    return errors, warnings, found_docs


def validate_required_sections(content, required_sections, doc_name):
    """éªŒè¯å¿…éœ€ç« èŠ‚"""
    errors = []
    warnings = []

    for section in required_sections:
        # åŒ¹é…äºŒçº§æˆ–ä¸‰çº§æ ‡é¢˜ï¼ˆæ”¯æŒå¸¦åºå·ã€emojiå’Œä¸å¸¦åºå·çš„æƒ…å†µï¼‰
        # ä½¿ç”¨ .*? æ¥åŒ¹é…å¯èƒ½å­˜åœ¨çš„emojiã€åºå·ç­‰å‰ç¼€

        # Pattern 1: ## [ä»»æ„å‰ç¼€] ç« èŠ‚å
        # ä¾‹å¦‚: ## å¿«é€Ÿå¯¼èˆª, ## ğŸ“‹ å¿«é€Ÿå¯¼èˆª
        pattern1 = f"^##\\s+(?!#).*?{re.escape(section)}"

        # Pattern 2: ### [ä»»æ„å‰ç¼€] ç« èŠ‚å
        pattern2 = f"^###\\s+(?!#).*?{re.escape(section)}"

        if not (re.search(pattern1, content, re.MULTILINE) or
                re.search(pattern2, content, re.MULTILINE)):
            errors.append(f"{doc_name}: ç¼ºå°‘å¿…éœ€ç« èŠ‚ã€Œ{section}ã€")

    return errors, warnings


def validate_mermaid_diagrams(content, min_count, doc_name):
    """éªŒè¯mermaidå›¾æ•°é‡å’Œè´¨é‡"""
    errors = []
    warnings = []

    # æŸ¥æ‰¾æ‰€æœ‰mermaidä»£ç å—
    mermaid_blocks = re.findall(r'```mermaid\s+(.*?)```', content, re.DOTALL)

    if len(mermaid_blocks) < min_count:
        errors.append(
            f"{doc_name}: mermaidå›¾æ•°é‡ä¸è¶³ï¼ˆéœ€è¦â‰¥{min_count}ä¸ªï¼Œå®é™…{len(mermaid_blocks)}ä¸ªï¼‰"
        )
        return errors, warnings

    # æ£€æŸ¥æ¯ä¸ªmermaidå›¾çš„è´¨é‡
    for i, block in enumerate(mermaid_blocks, 1):
        block = block.strip()

        # æ£€æŸ¥å›¾ç±»å‹
        valid_types = ['graph', 'flowchart', 'sequenceDiagram', 'classDiagram', 'stateDiagram']
        if not any(block.startswith(t) for t in valid_types):
            warnings.append(f"{doc_name}: ç¬¬{i}ä¸ªmermaidå›¾ç¼ºå°‘å›¾ç±»å‹å£°æ˜")

        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if len(block) < 20:
            errors.append(f"{doc_name}: ç¬¬{i}ä¸ªmermaidå›¾å†…å®¹è¿‡å°‘æˆ–ä¸ºç©º")

        # ç²¾ç®€åçš„æµç¨‹å›¾ä¸å¼ºåˆ¶è¦æ±‚Note overæ ‡æ³¨ï¼ˆAIä¼šä»ä»£ç ä½ç½®è¡¨æ ¼æ¨æ–­ï¼‰
        # åŸç­–ç•¥ï¼šæ£€æŸ¥ä»£ç ä½ç½®æ ‡æ³¨
        # æ–°ç­–ç•¥ï¼šä»…åœ¨è¡¨æ ¼åŒ–å®ç°æ­¥éª¤ä¸­éªŒè¯ä»£ç ä½ç½®

    return errors, warnings


def validate_interface_table(content, doc_name):
    """éªŒè¯æ¥å£è¡¨æ ¼ï¼ˆä»…interfaces.mdéœ€è¦ï¼‰"""
    errors = []
    warnings = []

    if doc_name != "interfaces.md":
        return errors, warnings

    # æŸ¥æ‰¾æ¥å£æ€»è§ˆç« èŠ‚ï¼ˆæ”¯æŒemojiã€åºå·ç­‰ä»»æ„å‰ç¼€ï¼‰
    section_match = re.search(
        r'##\s+(?!#).*?æ¥å£æ€»è§ˆ\s+(.*?)(?=^##\s+(?!#)|\Z)',
        content, re.DOTALL | re.MULTILINE
    )

    if not section_match:
        errors.append(f"{doc_name}: æœªæ‰¾åˆ°ã€Œæ¥å£æ€»è§ˆã€ç« èŠ‚")
        return errors, warnings

    section_content = section_match.group(1)

    # æ£€æŸ¥æ¥å£è¡¨æ ¼
    table_pattern = r'\|.*\|.*\|'
    tables = re.findall(table_pattern, section_content)

    if not tables:
        errors.append(f"{doc_name}: ã€Œæ¥å£æ€»è§ˆã€ç« èŠ‚ç¼ºå°‘æ¥å£è¡¨æ ¼")
        return errors, warnings

    # æŸ¥æ‰¾åŒ…å«æ‰€æœ‰å¿…éœ€åˆ—çš„è¡¨å¤´ï¼ˆæ”¯æŒ\"æ¥å£åç§°\"æˆ–\"æ¥å£è·¯å¾„\"æˆ–\"æ¥å£\"ï¼‰
    required_columns = ['åè®®', 'åŠŸèƒ½', 'ä»£ç ä½ç½®']
    header_line = None

    for line in tables:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¥å£åç§°ç›¸å…³çš„åˆ—
        has_interface = 'æ¥å£åç§°' in line or 'æ¥å£è·¯å¾„' in line or ('æ¥å£' in line and 'æ¥å£æ•°é‡' not in line)
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åè®®ã€åŠŸèƒ½ã€ä»£ç ä½ç½®
        has_all_required = all(col in line for col in required_columns)

        if has_interface and has_all_required:
            header_line = line
            break

    if not header_line:
        warnings.append(
            f"{doc_name}: æ¥å£è¡¨æ ¼ç¼ºå°‘å…³é”®åˆ—ï¼ŒæœŸæœ›åŒ…å«: "
            f"æ¥å£åç§°(æˆ–æ¥å£è·¯å¾„)ã€åè®®ã€åŠŸèƒ½ã€ä»£ç ä½ç½®\n"
            f"  å‚è€ƒæ ¼å¼: | æ¥å£åç§° | åè®® | åŠŸèƒ½ | ä»£ç ä½ç½® | è®¤è¯ |"
        )

    # ç»Ÿè®¡æ¥å£æ•°é‡
    interface_count = 0
    for row in tables[1:]:  # è·³è¿‡è¡¨å¤´
        if '---' not in row and row.strip():
            interface_count += 1

    if interface_count == 0:
        errors.append(f"{doc_name}: æ¥å£è¡¨æ ¼ä¸ºç©ºï¼Œè¯·æ·»åŠ æ¥å£å®šä¹‰")
    if 0 < interface_count < 3:
        warnings.append(
            f"{doc_name}: æ¥å£æ•°é‡è¾ƒå°‘ï¼ˆ{interface_count}ä¸ªï¼‰ï¼Œè¯·ç¡®è®¤æ˜¯å¦æœ‰é—æ¼"
        )

    return errors, warnings


def validate_code_locations(content, doc_name):
    """éªŒè¯ä»£ç ä½ç½®æ ‡æ³¨"""
    errors = []
    warnings = []

    # æå–æ‰€æœ‰ä»£ç ä½ç½®æ ‡æ³¨
    # æ ¼å¼1: è¡¨æ ¼ä¸­çš„ `file.go:10-50`
    table_locs = re.findall(r'`([^`]+\.(?:go|java|py|js|ts|tsx|jsx|cpp|c|h|hpp):\d+-\d+)`', content)

    # æ ¼å¼2: Note overä¸­çš„ (file.go:10-50)
    note_locs = re.findall(
        r'Note over [^:]+:[^(]*\(([^)]+\.(?:go|java|py|js|ts|tsx|jsx|cpp|c|h|hpp):\d+-\d+)\)',
        content
    )

    # æ ¼å¼3: èŠ‚ç‚¹ä¸­çš„ file.go:10-50
    node_locs = re.findall(r'<br/>([^<]+\.(?:go|java|py|js|ts|tsx|jsx|cpp|c|h|hpp):\d+-\d+)\]', content)

    all_locs = table_locs + note_locs + node_locs

    if not all_locs:
        # interfaces.mdå’Œimplementation.mdå¿…é¡»æœ‰ä»£ç ä½ç½®æ ‡æ³¨
        if doc_name in ["interfaces.md", "implementation.md"]:
            warnings.append(
                f"{doc_name}: æœªæ‰¾åˆ°ä»£ç ä½ç½®æ ‡æ³¨\n"
                f"  å»ºè®®æ ‡æ³¨æ ¼å¼: `logic/user.go:25-60`"
            )
        return errors, warnings

    # éªŒè¯æ ¼å¼ï¼ˆæ”¯æŒæ›´å¤šè¯­è¨€æ‰©å±•åï¼‰
    valid_pattern = r'^[\w/.-]+\.(go|java|py|js|ts|tsx|jsx|cpp|c|h|hpp):\d+-\d+$'
    invalid_locs = []

    for loc in all_locs:
        loc = loc.strip()
        if not re.match(valid_pattern, loc):
            invalid_locs.append(loc)

    if invalid_locs:
        errors.append(
            f"{doc_name}: å‘ç°{len(invalid_locs)}å¤„ä»£ç ä½ç½®æ ¼å¼ä¸è§„èŒƒ:\n" +
            "\n".join(f"  - {loc}" for loc in invalid_locs[:3]) +
            ("\n  ..." if len(invalid_locs) > 3 else "")
        )

    # æ£€æŸ¥è¡Œå·åˆç†æ€§ï¼ˆç²¾ç®€åå…è®¸æ›´å¤§è·¨åº¦ï¼Œå› ä¸ºåˆ é™¤äº†ä»£ç ç‰‡æ®µï¼‰
    for loc in all_locs:
        match = re.search(r':(\d+)-(\d+)$', loc)
        if match:
            start, end = int(match.group(1)), int(match.group(2))
            if start > end:
                errors.append(f"{doc_name}: ä»£ç ä½ç½®è¡Œå·é”™è¯¯ï¼ˆèµ·å§‹>ç»“æŸï¼‰: {loc}")
            # ç²¾ç®€ååˆ é™¤äº†ä»£ç ç‰‡æ®µï¼ŒAIä¼šè‡ªå·±read_fileï¼Œæ‰€ä»¥æ”¾å®½è·¨åº¦é™åˆ¶åˆ°500è¡Œ
            elif end - start > 500:
                warnings.append(f"{doc_name}: ä»£ç è·¨åº¦è¿‡å¤§ï¼ˆ>{end-start}è¡Œï¼‰: {loc}")

    return errors, warnings


def validate_placeholders(content, doc_name):
    """æ£€æŸ¥å ä½ç¬¦"""
    errors = []
    warnings = []

    for keyword in PLACEHOLDER_KEYWORDS:
        if re.search(keyword, content, re.IGNORECASE):
            warnings.append(f"{doc_name}: å‘ç°å ä½ç¬¦ã€Œ{keyword}ã€ï¼Œå»ºè®®è¡¥å……å®Œæ•´å†…å®¹")

    return errors, warnings


def validate_single_document(file_path, doc_name, config):
    """éªŒè¯å•ä¸ªæ–‡æ¡£"""
    errors = []
    warnings = []

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except (IOError, OSError) as e:
        errors.append(f"{doc_name}: è¯»å–æ–‡ä»¶å¤±è´¥ - {str(e)}")
        return errors, warnings

    # 1. éªŒè¯å¿…éœ€ç« èŠ‚
    errs, warns = validate_required_sections(
        content, config["required_sections"], doc_name
    )
    errors.extend(errs)
    warnings.extend(warns)

    # 2. éªŒè¯mermaidå›¾
    if config["min_mermaid"] > 0:
        errs, warns = validate_mermaid_diagrams(
            content, config["min_mermaid"], doc_name
        )
        errors.extend(errs)
        warnings.extend(warns)

    # 3. éªŒè¯æ¥å£è¡¨æ ¼ï¼ˆä»…interfaces.mdï¼‰
    errs, warns = validate_interface_table(content, doc_name)
    errors.extend(errs)
    warnings.extend(warns)

    # 4. éªŒè¯ä»£ç ä½ç½®æ ‡æ³¨
    errs, warns = validate_code_locations(content, doc_name)
    errors.extend(errs)
    warnings.extend(warns)

    # 5. æ£€æŸ¥å ä½ç¬¦
    errs, warns = validate_placeholders(content, doc_name)
    errors.extend(errs)
    warnings.extend(warns)

    return errors, warnings


def validate_wiki(doc_path):
    """ä¸»éªŒè¯å‡½æ•°

    Args:
        doc_path: docç›®å½•è·¯å¾„ æˆ– å•ä¸ªæ–‡æ¡£æ–‡ä»¶è·¯å¾„

    Returns:
        éªŒè¯ç»“æœå­—å…¸
    """
    path = Path(doc_path)

    # åˆ¤æ–­æ˜¯å•æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if path.is_file():
        # å•æ–‡ä»¶éªŒè¯æ¨¡å¼
        return validate_single_file(doc_path)
    if path.is_dir():
        # ç›®å½•éªŒè¯æ¨¡å¼ï¼ˆåŸé€»è¾‘ï¼‰
        return validate_directory(doc_path)
    return {
        "success": False,
        "doc_type": "æœªçŸ¥",
        "errors": [f"è·¯å¾„ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {doc_path}"],
        "warnings": [],
        "suggestions": ["æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®"],
        "stats": {"error_count": 1, "warning_count": 0}
    }


def validate_single_file(file_path):
    """éªŒè¯å•ä¸ªæ–‡æ¡£æ–‡ä»¶

    Args:
        file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ doc/README.mdï¼‰

    Returns:
        éªŒè¯ç»“æœå­—å…¸
    """
    path = Path(file_path)
    doc_name = path.name

    # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ–‡æ¡£ç±»å‹
    if doc_name not in DOC_STRUCTURE:
        return {
            "success": False,
            "doc_type": "å•æ–‡æ¡£éªŒè¯",
            "errors": [f"ä¸æ”¯æŒçš„æ–‡æ¡£ç±»å‹: {doc_name}ï¼Œæ”¯æŒçš„ç±»å‹: {', '.join(DOC_STRUCTURE.keys())}"],
            "warnings": [],
            "suggestions": ["è¯·éªŒè¯ 1+3 æ–‡æ¡£ç»“æ„ä¸­çš„æ–‡æ¡£"],
            "stats": {"error_count": 1, "warning_count": 0}
        }

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not path.exists():
        return {
            "success": False,
            "doc_type": "å•æ–‡æ¡£éªŒè¯",
            "errors": [f"æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"],
            "warnings": [],
            "suggestions": [f"åˆ›å»º {doc_name} æ–‡ä»¶"],
            "stats": {"error_count": 1, "warning_count": 0}
        }

    # éªŒè¯æ–‡æ¡£
    config = DOC_STRUCTURE[doc_name]
    errors, warnings = validate_single_document(str(path), doc_name, config)

    # æ„å»ºä¿®å¤å»ºè®®
    suggestions = []
    if errors:
        suggestions.append(f"è¯·ä¿®å¤ {doc_name} çš„é”™è¯¯åé‡æ–°éªŒè¯")
        if any("ç¼ºå°‘å¿…éœ€ç« èŠ‚" in e for e in errors):
            suggestions.append(f"å‚è€ƒ assets/templates/{doc_name}.template è¡¥å……ç¼ºå¤±ç« èŠ‚")
        if any("ä»£ç ä½ç½®" in e for e in errors):
            suggestions.append("å‚è€ƒæ ¼å¼: `logic/user.go:25-60`")

    if warnings and not errors:
        suggestions.append("å»ºè®®æ”¹è¿›è­¦å‘Šé¡¹åå†ç»§ç»­")

    # è¿”å›ç»“æœ
    return {
        "success": len(errors) == 0,
        "doc_type": f"å•æ–‡æ¡£éªŒè¯ - {doc_name}",
        "file_path": str(path),
        "doc_description": config["description"],
        "errors": errors,
        "warnings": warnings,
        "suggestions": suggestions,
        "stats": {
            "error_count": len(errors),
            "warning_count": len(warnings),
            "docs_validated": 1
        }
    }


def validate_directory(doc_dir):
    """éªŒè¯æ•´ä¸ªæ–‡æ¡£ç›®å½•ï¼ˆåŸé€»è¾‘ï¼‰

    Args:
        doc_dir: docç›®å½•è·¯å¾„
    """
    all_errors = []
    all_warnings = []

    # 1. éªŒè¯ç›®å½•ç»“æ„å’Œæ–‡æ¡£å­˜åœ¨æ€§
    errors, warnings, found_docs = validate_directory_structure(doc_dir)
    all_errors.extend(errors)
    all_warnings.extend(warnings)

    if not found_docs:
        return {
            "success": False,
            "doc_type": "1+3æ–‡æ¡£ç»“æ„",
            "errors": all_errors,
            "warnings": all_warnings,
            "suggestions": [
                "åˆ›å»ºç¼ºå¤±çš„æ–‡æ¡£æ–‡ä»¶",
                "å‚è€ƒ references/project_doc_init.md ç”Ÿæˆæ–‡æ¡£"
            ]
        }

    # 2. éªŒè¯æ¯ä¸ªæ–‡æ¡£
    for doc_name, file_path in found_docs.items():
        config = DOC_STRUCTURE[doc_name]
        errors, warnings = validate_single_document(file_path, doc_name, config)
        all_errors.extend(errors)
        all_warnings.extend(warnings)

    # 3. æ„å»ºä¿®å¤å»ºè®®
    suggestions = []
    if all_errors:
        suggestions.append("è¯·ä¿®å¤ä¸Šè¿°é”™è¯¯åé‡æ–°éªŒè¯")
        if any("ç¼ºå°‘æ–‡æ¡£" in e for e in all_errors):
            suggestions.append("å‚è€ƒ assets/templates/*.md.template åˆ›å»ºç¼ºå¤±æ–‡æ¡£")
        if any("ç¼ºå°‘å¿…éœ€ç« èŠ‚" in e for e in all_errors):
            suggestions.append("å‚è€ƒ references/project_doc_init.md è¡¥å……ç¼ºå¤±ç« èŠ‚")
        if any("ä»£ç ä½ç½®" in e for e in all_errors):
            suggestions.append("å‚è€ƒæ ¼å¼: `logic/user.go:25-60`")

    if all_warnings and not all_errors:
        suggestions.append("å»ºè®®æ”¹è¿›è­¦å‘Šé¡¹åå†æäº¤å®¡æ‰¹")

    # 4. è¿”å›ç»“æœ
    return {
        "success": len(all_errors) == 0,
        "doc_type": "1+3æ–‡æ¡£ç»“æ„",
        "errors": all_errors,
        "warnings": all_warnings,
        "suggestions": suggestions,
        "stats": {
            "error_count": len(all_errors),
            "warning_count": len(all_warnings),
            "docs_found": len(found_docs),
            "docs_expected": 4
        }
    }


def _parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='éªŒè¯ wiki æ–‡æ¡£æ ¼å¼è§„èŒƒï¼ˆ1+3æ–‡æ¡£ç»“æ„ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ–‡æ¡£ç»“æ„è¯´æ˜ï¼š
  doc/
  â”œâ”€â”€ README.md          # å…¥å£ç´¢å¼•
  â”œâ”€â”€ architecture.md    # æ¶æ„æ ¸å¿ƒ
  â”œâ”€â”€ interfaces.md      # æ¥å£æ±‡æ€»
  â””â”€â”€ implementation.md  # å®ç°ç»†èŠ‚

ä½¿ç”¨ç¤ºä¾‹ï¼š
  # éªŒè¯æ•´ä¸ªç›®å½•
  python3 validate_wiki.py doc/

  # éªŒè¯å•ä¸ªæ–‡æ¡£
  python3 validate_wiki.py doc/README.md
  python3 validate_wiki.py doc/architecture.md
  python3 validate_wiki.py doc/interfaces.md
  python3 validate_wiki.py doc/implementation.md

å¢å¼ºæ£€æŸ¥æ¨¡å¼ï¼ˆ--enhancedï¼‰ï¼šæš‚æ—¶ä¿ç•™å…¼å®¹æ€§ï¼Œæœªå®ç°
        """
    )
    parser.add_argument(
        'doc_path',
        help='æ–‡æ¡£ç›®å½•è·¯å¾„ï¼ˆå¦‚ doc/ï¼‰æˆ–å•ä¸ªæ–‡æ¡£æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ doc/README.mdï¼‰'
    )
    parser.add_argument(
        '--json',
        action='store_true',
        help='JSON æ ¼å¼è¾“å‡ºï¼ˆç”¨äºè‡ªåŠ¨åŒ–ï¼‰'
    )
    parser.add_argument(
        '--quiet',
        action='store_true',
        help='é™é»˜æ¨¡å¼ï¼ˆä»…è¾“å‡º JSONï¼‰'
    )
    parser.add_argument(
        '--enhanced',
        action='store_true',
        help='å¯ç”¨å¢å¼ºè´¨é‡æ£€æŸ¥ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰'
    )

    return parser.parse_args()


def _print_header(doc_path, doc_type):
    """æ‰“å°éªŒè¯å¤´éƒ¨ä¿¡æ¯"""
    print("\n" + "="*60)
    print(f"ğŸ“„ éªŒè¯ wiki æ–‡æ¡£ï¼š{doc_path}")
    print(f"   éªŒè¯æ¨¡å¼ï¼š{doc_type}")
    print("="*60 + "\n")


def _print_errors(errors):
    """æ‰“å°é”™è¯¯ä¿¡æ¯"""
    if not errors:
        return

    print("âŒ å‘ç°ä»¥ä¸‹é”™è¯¯ï¼ˆå¿…é¡»ä¿®å¤ï¼‰ï¼š\n")
    for i, error in enumerate(errors, 1):
        print(f"  {i}. {error}")
    print()


def _print_warnings(warnings):
    """æ‰“å°è­¦å‘Šä¿¡æ¯"""
    if not warnings:
        return

    print("âš ï¸  å‘ç°ä»¥ä¸‹è­¦å‘Šï¼ˆå»ºè®®æ”¹è¿›ï¼‰ï¼š\n")
    for i, warning in enumerate(warnings, 1):
        print(f"  {i}. {warning}")
    print()


def _print_summary(result):
    """æ‰“å°éªŒè¯æ€»ç»“"""
    stats = result.get("stats", {})
    errors = result.get("errors", [])
    warnings = result.get("warnings", [])

    print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"  - æ–‡æ¡£æ•°é‡ï¼š{stats.get('docs_found', 0)}/{stats.get('docs_expected', 4)}")
    print(f"  - é”™è¯¯æ•°é‡ï¼š{stats.get('error_count', 0)}")
    print(f"  - è­¦å‘Šæ•°é‡ï¼š{stats.get('warning_count', 0)}")
    print()

    if not errors and not warnings:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼wiki æ–‡æ¡£æ ¼å¼è§„èŒƒã€‚\n")
    elif not errors:
        print("âš ï¸  æ ¼å¼æ£€æŸ¥é€šè¿‡ï¼Œä½†å­˜åœ¨è­¦å‘Šé¡¹ï¼Œå»ºè®®æ”¹è¿›åå†æäº¤å®¡æ‰¹ã€‚\n")
    else:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼šå‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼Œ{len(warnings)} ä¸ªè­¦å‘Š\n")


def _print_suggestions(suggestions):
    """æ‰“å°ä¿®å¤å»ºè®®"""
    if not suggestions:
        return

    print("ğŸ’¡ ä¿®å¤å»ºè®®ï¼š\n")
    for i, suggestion in enumerate(suggestions, 1):
        print(f"  {i}. {suggestion}")
    print()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    args = _parse_arguments()

    # æ‰§è¡ŒéªŒè¯
    result = validate_wiki(args.doc_path)

    # è¾“å‡ºç»“æœ
    if args.json or args.quiet:
        print(json.dumps(result, ensure_ascii=False, indent=2))
        sys.exit(0 if result["success"] else 1)
    else:
        _print_header(args.doc_path, result.get("doc_type", "æœªçŸ¥"))
        _print_errors(result.get("errors", []))
        _print_warnings(result.get("warnings", []))
        _print_summary(result)
        _print_suggestions(result.get("suggestions", []))
        sys.exit(0 if result["success"] else 1)


if __name__ == "__main__":
    main()
